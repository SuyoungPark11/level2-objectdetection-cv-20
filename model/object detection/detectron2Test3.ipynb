{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.data import DatasetCatalog, DatasetMapper, build_detection_test_loader\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.modeling import BACKBONE_REGISTRY, Backbone, ShapeSpec\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.utils.events import EventStorage\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "import timm\n",
    "import sys\n",
    "# 추가적으로 필요한 import\n",
    "from detectron2.evaluation import DatasetEvaluators\n",
    "import logging\n",
    "logging.getLogger(\"detectron2\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"detectron2\").disabled = True\n",
    "\n",
    "@BACKBONE_REGISTRY.register()\n",
    "class TimmBackbone(Backbone):\n",
    "    def __init__(self, cfg, input_shape):\n",
    "        super().__init__()\n",
    "        model_name = cfg.MODEL.BACKBONE.TIMM_MODEL\n",
    "        self.model = timm.create_model(model_name, features_only=True, pretrained=True)\n",
    "        feature_info = self.model.feature_info.get_dicts(keys=['num_chs', 'reduction'])\n",
    "        \n",
    "        self.out_channels = 256\n",
    "        self.convs = nn.ModuleDict()\n",
    "        for i, info in enumerate(feature_info):\n",
    "            self.convs[f\"p{i+2}\"] = nn.Conv2d(info['num_chs'], self.out_channels, kernel_size=1)\n",
    "        \n",
    "        # P6, P7 레벨 추가 (RetinaNet용)\n",
    "        self.p6 = nn.Conv2d(feature_info[-1]['num_chs'], self.out_channels, kernel_size=3, stride=2, padding=1)\n",
    "        self.p7 = nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self._out_features = [\"p2\", \"p3\", \"p4\", \"p5\", \"p6\", \"p7\"]\n",
    "        self._out_feature_channels = {name: self.out_channels for name in self._out_features}\n",
    "        self._out_feature_strides = {f\"p{i+2}\": info['reduction'] for i, info in enumerate(feature_info)}\n",
    "        self._out_feature_strides[\"p6\"] = self._out_feature_strides[\"p5\"] * 2\n",
    "        self._out_feature_strides[\"p7\"] = self._out_feature_strides[\"p6\"] * 2\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.model(x)\n",
    "        out = {f\"p{i+2}\": self.convs[f\"p{i+2}\"](feature) for i, feature in enumerate(features)}\n",
    "        p6 = self.p6(features[-1])\n",
    "        p7 = self.p7(F.relu(p6))\n",
    "        out[\"p6\"] = p6\n",
    "        out[\"p7\"] = p7\n",
    "        return out\n",
    "\n",
    "    def output_shape(self):\n",
    "        return {\n",
    "            name: ShapeSpec(\n",
    "                channels=self._out_feature_channels[name], stride=self._out_feature_strides[name]\n",
    "            )\n",
    "            for name in self._out_features\n",
    "        }\n",
    "\n",
    "def setup_cfg(model_type):\n",
    "    cfg = get_cfg()\n",
    "    if model_type == \"Cascade R-CNN\":\n",
    "        cfg.merge_from_file(model_zoo.get_config_file(\"Misc/cascade_mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "        cfg.MODEL.FPN.IN_FEATURES = [\"p2\", \"p3\", \"p4\", \"p5\", \"p6\"]\n",
    "    elif model_type == \"RetinaNet\":\n",
    "        print(\"??\")\n",
    "        cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/retinanet_R_50_FPN_3x.yaml\"))\n",
    "        cfg.MODEL.FPN.IN_FEATURES = [\"p2\", \"p3\", \"p4\", \"p5\", \"p6\", \"p7\"]\n",
    "    else:  # FPN-based Faster R-CNN\n",
    "        cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "        cfg.MODEL.FPN.IN_FEATURES = [\"p2\", \"p3\", \"p4\", \"p5\", \"p6\"]\n",
    "    print(\"?\")\n",
    "    cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
    "    cfg.DATASETS.TEST = (\"my_dataset_val\",)\n",
    "\n",
    "    cfg.MODEL.BACKBONE.NAME = \"TimmBackbone\"\n",
    "    cfg.MODEL.BACKBONE.TIMM_MODEL = \"resnet50\"    \n",
    "    \n",
    "    cfg.MODEL.FPN.OUT_CHANNELS = 256     \n",
    "\n",
    "    cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[32], [64], [128], [256], [512]]    \n",
    "    cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.5, 1.0, 2.0]]\n",
    "\n",
    "    cfg.MODEL.RPN.IN_FEATURES = cfg.MODEL.FPN.IN_FEATURES\n",
    "\n",
    "    cfg.MODEL.WEIGHTS = \"\"\n",
    "    \n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 10\n",
    "    cfg.INPUT.MIN_SIZE_TRAIN = (1024,)\n",
    "    cfg.INPUT.MAX_SIZE_TRAIN = 1024\n",
    "    cfg.INPUT.MIN_SIZE_TEST = 1024\n",
    "    cfg.INPUT.MAX_SIZE_TEST = 1024\n",
    "    cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "    cfg.SOLVER.BASE_LR = 0.003\n",
    "    # epoch 설정\n",
    "    dataset_size = 4883\n",
    "    num_epochs = 1  # 원하는 epoch 수\n",
    "    iterations_per_epoch = dataset_size // cfg.SOLVER.IMS_PER_BATCH\n",
    "    cfg.SOLVER.MAX_ITER = iterations_per_epoch * num_epochs\n",
    "    cfg.TEST.EVAL_PERIOD = num_epochs\n",
    "\n",
    "    # cuDNN 벤치마크 비활성화\n",
    "    # torch.backends.cudnn.enabled = False\n",
    "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "\n",
    "    # 학습률 스케줄 조정 (선택사항)\n",
    "    #cfg.SOLVER.STEPS = (iterations_per_epoch * 30, iterations_per_epoch * 40) \n",
    "\n",
    "    cfg.MODEL.MASK_ON = False\n",
    "\n",
    "    return cfg\n",
    "    \n",
    "image_dir = '../../dataset'\n",
    "json_file_path = '../../dataset/train.json'\n",
    "\n",
    "# 데이터셋 등록 (COCO 형식 가정)\n",
    "register_coco_instances(\"my_dataset_train\", {}, image_dir + \"/train.json\", image_dir)\n",
    "register_coco_instances(\"my_dataset_val\", {}, image_dir + \"/test.json\", image_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "??\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "COCO-Detection/retinanet_R_50_FPN_3x.yaml not available in Model Zoo!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 90\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 학습 완료\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     89\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\n\u001b[0;32m---> 90\u001b[0m cfg_retinanet \u001b[38;5;241m=\u001b[39m \u001b[43msetup_cfg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRetinaNet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 77\u001b[0m, in \u001b[0;36msetup_cfg\u001b[0;34m(model_type)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetinaNet\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m??\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 77\u001b[0m     cfg\u001b[38;5;241m.\u001b[39mmerge_from_file(\u001b[43mmodel_zoo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCOCO-Detection/retinanet_R_50_FPN_3x.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     78\u001b[0m     cfg\u001b[38;5;241m.\u001b[39mMODEL\u001b[38;5;241m.\u001b[39mFPN\u001b[38;5;241m.\u001b[39mIN_FEATURES \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp3\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp6\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp7\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# FPN-based Faster R-CNN\u001b[39;00m\n",
      "File \u001b[0;32m~/level2-objectdetection-cv-20/code/baseline/detectron2/detectron2/model_zoo/model_zoo.py:143\u001b[0m, in \u001b[0;36mget_config_file\u001b[0;34m(config_path)\u001b[0m\n\u001b[1;32m    139\u001b[0m cfg_file \u001b[38;5;241m=\u001b[39m pkg_resources\u001b[38;5;241m.\u001b[39mresource_filename(\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetectron2.model_zoo\u001b[39m\u001b[38;5;124m\"\u001b[39m, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigs\u001b[39m\u001b[38;5;124m\"\u001b[39m, config_path)\n\u001b[1;32m    141\u001b[0m )\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(cfg_file):\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m not available in Model Zoo!\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(config_path))\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cfg_file\n",
      "\u001b[0;31mRuntimeError\u001b[0m: COCO-Detection/retinanet_R_50_FPN_3x.yaml not available in Model Zoo!"
     ]
    }
   ],
   "source": [
    "\n",
    "def sample_train_data(dataset_dicts, sample_ratio=0.2):\n",
    "    \"\"\"학습 데이터의 일부를 샘플링합니다.\"\"\"\n",
    "    sampled_data = random.sample(dataset_dicts, int(len(dataset_dicts) * sample_ratio))\n",
    "    return sampled_data\n",
    "\n",
    "def evaluate_on_train_set(cfg, model, dataset_name):\n",
    "    dataset_dicts = DatasetCatalog.get(dataset_name)\n",
    "    sampled_data = sample_train_data(dataset_dicts)\n",
    "    \n",
    "    mapper = DatasetMapper(cfg, is_train=False)\n",
    "    sampled_loader = build_detection_test_loader(sampled_data, mapper=mapper)\n",
    "    \n",
    "    evaluator = COCOEvaluator(dataset_name, cfg, False, output_dir=cfg.OUTPUT_DIR)\n",
    "\n",
    "    # tqdm을 사용하여 평가 진행 상황 표시\n",
    "    results = inference_on_dataset(model, sampled_loader, evaluator)\n",
    "   \n",
    "    # 'bbox' 키에서 클래스별 AP와 AR 값을 추출\n",
    "    class_metrics = {}\n",
    "    for class_id, metrics in results['bbox'].items():\n",
    "        if isinstance(class_id, int):  # 클래스 ID인 경우만 처리\n",
    "            class_metrics[class_id] = {\n",
    "                'AP': metrics['AP'],\n",
    "                'AR': metrics['AR']\n",
    "            }\n",
    "    \n",
    "    return class_metrics\n",
    "\n",
    "def calculate_mAP(metrics):\n",
    "    ap_values = [values['AP'] for class_id, values in metrics.items() if isinstance(class_id, int)]\n",
    "    return sum(ap_values) / len(ap_values) if ap_values else 0\n",
    "\n",
    "def train_model(cfg, model_name):\n",
    "    trainer = DefaultTrainer(cfg)\n",
    "    trainer.resume_or_load(resume=False)\n",
    "\n",
    "    # 모델명에 맞는 디렉토리 생성\n",
    "    model_output_dir = os.path.join(cfg.OUTPUT_DIR, model_name)\n",
    "    os.makedirs(model_output_dir, exist_ok=True)\n",
    "    cfg.OUTPUT_DIR = model_output_dir\n",
    "\n",
    "    checkpointer = DetectionCheckpointer(trainer.model, save_dir=cfg.OUTPUT_DIR)\n",
    "\n",
    "    loss_window = 20  # 최근 20개 iteration의 평균 손실을 계산합니다\n",
    "    eval_period = 1000  # 1000 iteration마다 평가를 수행합니다\n",
    "    save_period = 3000  # 5000 iteration마다 모델을 저장합니다\n",
    "    best_mAP = 0.\n",
    "\n",
    "    with EventStorage() as storage:\n",
    "        with tqdm(total=cfg.SOLVER.MAX_ITER, desc=f\"Training {model_name}\") as pbar:\n",
    "            for iteration in range(cfg.SOLVER.MAX_ITER):\n",
    "                trainer.run_step()\n",
    "                mAP = 0.\n",
    "                if (iteration + 1) % 2 == 0:\n",
    "                    losses = storage.histories()[\"total_loss\"].avg(loss_window)\n",
    "                    lr = trainer.optimizer.param_groups[0][\"lr\"]\n",
    "                    pbar.set_postfix({'loss': f'{losses:.4f}', 'lr': f'{lr:.6f}'})\n",
    "                \n",
    "                if (iteration + 1) % eval_period == 0:\n",
    "                    pbar.set_description(f\"Evaluating {model_name}\")\n",
    "                    metrics = evaluate_on_train_set(cfg, trainer.model, cfg.DATASETS.TRAIN[0])\n",
    "\n",
    "                    mAP = calculate_mAP(metrics)\n",
    "                    best_mAP = max(best_mAP, mAP)\n",
    "\n",
    "                    class_metrics = []\n",
    "                    for class_id, values in metrics.items():\n",
    "                        ap = values['AP']\n",
    "                        ar = values['AR']\n",
    "                        class_metrics.append(f\"C{class_id}: AP:{ap:.2f}, AR:{ar:.2f}\")\n",
    "                    \n",
    "                    class_metrics_str = \" | \".join(class_metrics)\n",
    "                    pbar.set_description(f\"Training {model_name} | {class_metrics_str}\")\n",
    "                \n",
    "                # 특정 iteration마다 모델 저장\n",
    "                if (iteration + 1) % save_period == 0:\n",
    "                    checkpointer.save(f\"{model_name}_iter_{iteration+1}_mAP_{mAP:.4f}\")\n",
    "                    print(f\"\\nSaved model at iteration {iteration+1}\")\n",
    "                \n",
    "                pbar.update(1)\n",
    "\n",
    "    # 학습이 끝난 후 최종 모델 저장\n",
    "    checkpointer.save(f\"{model_name}_final_mAP_{best_mAP:.4f}\")\n",
    "    print(f\"\\nSaved final model for {model_name}\")\n",
    "\n",
    "    print(f\"{model_name} 학습 완료\")\n",
    "\n",
    "\n",
    "sys.path\n",
    "cfg_retinanet = setup_cfg(\"RetinaNet\")\n",
    "# train_model(cfg_retinanet, \"RetinaNet\")\n",
    "# # Set up configurations and train models\n",
    "# cfg_fpn = setup_cfg(\"FPN-based Faster R-CNN\")\n",
    "# train_model(cfg_fpn, \"FPN-based Faster R-CNN\")\n",
    "\n",
    "# cfg_cascade = setup_cfg(\"Cascade R-CNN\")\n",
    "# train_model(cfg_cascade, \"Cascade R-CNN\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
